---
title: Features
---


## Improvements on DiskANN

TODO Transient index/disk index. periodic builds and its advantages etc


## Vector Similarity Functions

When creating a vector index in Upstash Vector, you have the flexibility to choose from different vector similarity functions. 
Each function yields distinct query results, catering to specific use cases. Here are the three supported similarity functions:

// TODO sancar usecases are from ChatGPT . Make sure they are correct or remove them.

#### Cosine Similarity

Cosine similarity measures the cosine of the angle between two vectors. It is particularly useful when the magnitude of the vectors is not essential, and the focus is on the orientation. 

**Use Cases:**
- **Natural Language Processing (NLP):** Ideal for comparing document embeddings or word vectors, as it captures semantic similarity irrespective of vector magnitude.
- **Recommendation Systems:** Effective in recommending items based on user preferences or content similarities.

**Score calculation:**

```1 / (1 + squareDistance(v1, v2)```

#### Euclidean Distance

Euclidean distance calculates the straight-line distance between two vectors in a multi-dimensional space. It is well-suited for scenarios where the magnitude of vectors is crucial, providing a measure of their spatial separation.

**Use Cases:**
- **Computer Vision:** Useful in image processing tasks, such as image recognition or object detection, where the spatial arrangement of features is significant.
- **Anomaly Detection:** Valuable for detecting anomalies in datasets, as it considers both the direction and magnitude of differences between vectors.


// TODO sancar: make sure that what `cosine` means here is clear after you understand it
**Score calculation:**
``` 1 + VectorUtil.cosine(v1, v2)) / 2;```

```
  @Override
  public float cosine(byte[] a, byte[] b) {
    // Note: this will not overflow if dim < 2^18, since max(byte * byte) = 2^14.
    int sum = 0;
    int norm1 = 0;
    int norm2 = 0;

    for (int i = 0; i < a.length; i++) {
      byte elem1 = a[i];
      byte elem2 = b[i];
      sum += elem1 * elem2;
      norm1 += elem1 * elem1;
      norm2 += elem2 * elem2;
    }
    return (float) (sum / Math.sqrt((double) norm1 * (double) norm2));
  }
```

#### Dot Product

The dot product measures the similarity by multiplying the corresponding components of two vectors and summing the results. It provides a measure of alignment between vectors.
**Use Cases:**
- **Machine Learning Models:** Commonly used in machine learning for tasks like sentiment analysis or classification, where feature alignment is critical.
- **Collaborative Filtering:** Effective in collaborative filtering scenarios, such as recommending items based on user behavior or preferences.

// TODO sancar: clear this part after understanding the calculation
**Score calculation:**
``` 
// Dot product score computed over signed bytes, scaled to be in [0, 1].
// divide by 2^14 (maximum absolute value of product of 2 signed bytes) * len
    float denom = (float) (a.length * (1 << 14));
(1 + (dotProduct(a, b) / denom)/2;
```

## Metadata

TODO FILL 

